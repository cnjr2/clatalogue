---
layout: post
title: "How do logistic regressions work?"
date: "2015-10-24"
categories: jekyll update
output:
    html_document:
        toc: true
    pdf_document:
        toc: true
---



# How do logistic regressions work?

Here is a nice tutorial on logistic regressions http://www.ats.ucla.edu/stat/r/dae/logit.htm.



## Prepare Session

We need to set some paths and read in some variables that contain the instructions on how to process the dataset.


{% highlight r %}
library("dplyr")
library("tidyr")
library("ggplot2")

#get the data
# system("wget http://www.ats.ucla.edu/stat/data/binary.csv")
mydata <- read.csv("binary.csv")
head(mydata)
{% endhighlight %}



{% highlight text %}
##   admit gre  gpa rank
## 1     0 380 3.61    3
## 2     1 660 3.67    3
## 3     1 800 4.00    1
## 4     1 640 3.19    4
## 5     0 520 2.93    4
## 6     1 760 3.00    2
{% endhighlight %}

## EDA

First we get a better feel for the data.

How does the **gpa** compare to the **gre**?


{% highlight r %}
p <- ggplot(
    data = mydata,
    mapping = aes(
        x = gre,
        y = gpa,
        color = factor(admit)
    )
)
p <- p +
    geom_point() +
    theme()
p
{% endhighlight %}

![plot of chunk gre_vs_gpa](https://dl.dropboxusercontent.com/u/6337901/jekyll/2015-10-24-gre/gre_vs_gpa-1.png) 

How is the **gpa** related to being admitted?


{% highlight r %}
p <- ggplot(
    data = mydata,
    mapping = aes(
        x = gpa,
        y = admit
    )
)
p <- p +
    geom_point() +
    theme()
p
{% endhighlight %}

![plot of chunk gpa_vs_admission](https://dl.dropboxusercontent.com/u/6337901/jekyll/2015-10-24-gre/gpa_vs_admission-1.png) 

How can we plot this better?


{% highlight r %}
p <- ggplot(
    data = mydata,
    mapping = aes(
        x = gpa,
        fill = factor(admit)
    )
)
p <- p +
    geom_histogram(position = "dodge") +
    theme()
p
{% endhighlight %}

![plot of chunk gpa_densities_admit_groups](https://dl.dropboxusercontent.com/u/6337901/jekyll/2015-10-24-gre/gpa_densities_admit_groups-1.png) 

## Setting a baseline

Trying a regression out of the box. We should be able to reproduce this.


{% highlight r %}
base <- ggplot(
    data = mydata,
    mapping = aes(
        x = gpa,
        y = admit
    )
)
base <- base +
    geom_smooth(method = "glm", family = "binomial") +
    geom_point() +
    theme()
base
{% endhighlight %}

![plot of chunk gpa_vs_admission_regression](https://dl.dropboxusercontent.com/u/6337901/jekyll/2015-10-24-gre/gpa_vs_admission_regression-1.png) 

## Build a predictor from scratch



{% highlight r %}
counts <- mydata %>%
    inner_join(
        data_frame(
            admit = c(0, 1),
            admit_chr = c("out", "join")
        ),
        by = "admit"
    ) %>%
    mutate(
        gpa_discrete = round(gpa, digits = 1)
    ) %>%
    count(admit_chr, gpa_discrete) %>%
    spread(
        key = admit_chr,
        value = n,
        fill = 0
    )

counts <- bind_cols(
    counts,
    data_frame(
        p = counts$join / (counts$join + counts$out),
        odds = p / (1 - p),
        log_odds = log(odds)
    )
)
{% endhighlight %}

- **p** is the probability of getting in
- **odds** informs about how much more likely it is to get in than not
- **log_odds** is the ln of the odds (in R log is the ln)

For example with a probability of 0.9 to get in, the odds to get in are `0.9/0.1 = 9`.



{% highlight r %}
linear_model <- lm(
    data = counts[!is.infinite(counts$log_odds),],
    weights = rowSums(counts[!is.infinite(counts$log_odds),c("join", "out")]),
    log_odds ~ gpa_discrete
)

p <- ggplot(data = counts)
p <- p +
    geom_point(aes(x = gpa_discrete, y = log_odds, size = join+out)) +
    geom_abline(
        mapping = aes(
            slope = linear_model$coefficients[[2]],
            intercept = linear_model$coefficients[[1]]
        )
    ) +
    theme()
p
{% endhighlight %}

![plot of chunk linear_model](https://dl.dropboxusercontent.com/u/6337901/jekyll/2015-10-24-gre/linear_model-1.png) 


{% highlight r %}
new_data <- data_frame(
    gpa_discrete = seq(2.3, 4, by = 0.1)
)

fit <- bind_cols(
    new_data,
    data_frame(
        log_odds = predict(
            linear_model,
            newdata = new_data,
            type = "response"
        ),
        odds = exp(log_odds),
        p = odds / (1 + odds),
        perc = p * 100
    )
)
{% endhighlight %}
The probabilities were converted to odds by the formular found at http://www.calculatorsoup.com/calculators/games/odds.php.


{% highlight r %}
base + geom_point(data = fit, aes(x = gpa_discrete, y = p), color = "red")
{% endhighlight %}

![plot of chunk comparison_with_baseline](https://dl.dropboxusercontent.com/u/6337901/jekyll/2015-10-24-gre/comparison_with_baseline-1.png) 

{% highlight r %}
general_linear_model <- glm(
    data = dplyr::rename(mydata, gpa_discrete = gpa),
    admit ~ gpa_discrete,
    family = "binomial"
)


glm_fit <- bind_cols(
    new_data,
    data_frame(
        glm_pred = predict(
            general_linear_model,
            newdata = new_data,
            type = "response"
        )
    )
)

final <- inner_join(fit, glm_fit, by = "gpa_discrete")

p <- ggplot(data = final)
p <- p +
    geom_abline(aes(slope = 1, intercept = 0)) +
    geom_point(aes(x = p, y = glm_pred)) +
    geom_text(
        aes(
            x = p,
            y = glm_pred,
            label = gpa_discrete
        ),
        hjust = 1.5,
        size = 3
    ) +
    labs(x = "home made", y = "normal glm") +
    theme()
p
{% endhighlight %}

![plot of chunk comparison_with_baseline](https://dl.dropboxusercontent.com/u/6337901/jekyll/2015-10-24-gre/comparison_with_baseline-2.png) 


